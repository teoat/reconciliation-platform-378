 input {
   beats {
     port => 5044
   }
 }

 filter {
   # Parse JSON logs first (from backend Rust services)
   if [message] =~ /^\{/ {
     json {
       source => "message"
       target => "parsed_json"
     }

     # Extract common fields from JSON
     if [parsed_json][timestamp] {
       date {
         match => [ "[parsed_json][timestamp]", "ISO8601" ]
         target => "@timestamp"
       }
     }

     if [parsed_json][level] {
       mutate {
         add_field => { "level" => "%{[parsed_json][level]}" }
       }
     }

     if [parsed_json][service] {
       mutate {
         add_field => { "service" => "%{[parsed_json][service]}" }
       }
     }

     if [parsed_json][message] {
       mutate {
         add_field => { "log_message" => "%{[parsed_json][message]}" }
       }
     }

     # Clean up
     mutate {
       remove_field => [ "parsed_json" ]
     }
   }

   # Parse plain text logs (fallback for services not using JSON)
   else {
     # Generic log parsing
     grok {
       match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:service} %{GREEDYDATA:log_message}" }
       overwrite => [ "message" ]
     }

     date {
       match => [ "timestamp", "ISO8601" ]
       remove_field => [ "timestamp" ]
     }
   }

   # Add common fields
   mutate {
     add_field => {
       "environment" => "${ENVIRONMENT:-development}"
       "host" => "%{host}"
     }
   }

   # Normalize log levels
   if [level] {
     mutate {
       lowercase => [ "level" ]
     }
   }
 }

 output {
   elasticsearch {
     hosts => ["elasticsearch:9200"]
     index => "reconciliation-logs-%{+YYYY.MM.dd}"
     document_type => "_doc"
   }

   # Also output to stdout for debugging
   stdout {
     codec => rubydebug
   }
 }
