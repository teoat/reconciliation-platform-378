name: Performance & Load Testing

on:
  schedule:
    - cron: "0 4 * * *" # Daily at 4 AM
  workflow_dispatch:
    inputs:
      target_url:
        description: "Target URL for load testing"
        required: false
        default: "http://localhost:2000"
      duration:
        description: "Test duration (e.g., 5m, 10m, 30m)"
        required: false
        default: "5m"
      virtual_users:
        description: "Maximum virtual users"
        required: false
        default: "100"

env:
  K6_VERSION: "0.49.0"
  LOCUST_VERSION: "2.24.0"

jobs:
  # ============================================================================
  # K6 Load Testing
  # ============================================================================
  k6-load-test:
    name: K6 Load Test
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: test
          POSTGRES_DB: reconciliation_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Build backend
        working-directory: backend
        run: cargo build --release

      - name: Start backend
        working-directory: backend
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/reconciliation_test
          REDIS_URL: redis://localhost:6379
          JWT_SECRET: test-secret
        run: |
          ./target/release/reconciliation-platform &
          sleep 10

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Run K6 smoke test
        run: |
          k6 run \
            --out json=k6-smoke-results.json \
            --summary-export=k6-smoke-summary.json \
            load-test/k6-load-test.js

      - name: Run K6 load test
        run: |
          k6 run \
            --out json=k6-load-results.json \
            --summary-export=k6-load-summary.json \
            -e API_URL=${{ github.event.inputs.target_url || 'http://localhost:2000' }} \
            load-test/k6-load-test.js

      - name: Upload K6 results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: k6-results
          path: |
            k6-*.json
          retention-days: 30

      - name: Check performance thresholds
        run: |
          # Parse summary and check thresholds
          P95=$(cat k6-load-summary.json | jq -r '.metrics.http_req_duration.values["p(95)"]')
          ERROR_RATE=$(cat k6-load-summary.json | jq -r '.metrics.http_req_failed.values.rate')
          
          echo "P95 Latency: ${P95}ms"
          echo "Error Rate: ${ERROR_RATE}"
          
          # Fail if P95 > 500ms or error rate > 1%
          if (( $(echo "$P95 > 500" | bc -l) )); then
            echo "::error::P95 latency ${P95}ms exceeds 500ms threshold"
            exit 1
          fi
          
          if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
            echo "::error::Error rate ${ERROR_RATE} exceeds 1% threshold"
            exit 1
          fi
        continue-on-error: true

  # ============================================================================
  # Locust Load Testing
  # ============================================================================
  locust-load-test:
    name: Locust Load Test
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: test
          POSTGRES_DB: reconciliation_test
        ports:
          - 5432:5432
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Locust
        run: pip install locust==${{ env.LOCUST_VERSION }}

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Build and start backend
        working-directory: backend
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/reconciliation_test
          REDIS_URL: redis://localhost:6379
          JWT_SECRET: test-secret
        run: |
          cargo build --release
          ./target/release/reconciliation-platform &
          sleep 10

      - name: Run Locust load test
        run: |
          locust \
            -f load-test/locustfile.py \
            --headless \
            --users ${{ github.event.inputs.virtual_users || '50' }} \
            --spawn-rate 10 \
            --run-time ${{ github.event.inputs.duration || '2m' }} \
            --host ${{ github.event.inputs.target_url || 'http://localhost:2000' }} \
            --html locust-report.html \
            --csv locust-results

      - name: Upload Locust results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: locust-results
          path: |
            locust-*.html
            locust-*.csv
          retention-days: 30

  # ============================================================================
  # Performance Report Generation
  # ============================================================================
  generate-report:
    name: Generate Performance Report
    runs-on: ubuntu-latest
    needs: [k6-load-test, locust-load-test]
    if: always()
    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: performance-results

      - name: Generate summary report
        run: |
          echo "## Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### K6 Results" >> $GITHUB_STEP_SUMMARY
          if [ -f "performance-results/k6-results/k6-load-summary.json" ]; then
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            P95=$(cat performance-results/k6-results/k6-load-summary.json | jq -r '.metrics.http_req_duration.values["p(95)"] // "N/A"')
            AVG=$(cat performance-results/k6-results/k6-load-summary.json | jq -r '.metrics.http_req_duration.values.avg // "N/A"')
            REQS=$(cat performance-results/k6-results/k6-load-summary.json | jq -r '.metrics.http_reqs.values.count // "N/A"')
            echo "| P95 Latency | ${P95}ms |" >> $GITHUB_STEP_SUMMARY
            echo "| Avg Latency | ${AVG}ms |" >> $GITHUB_STEP_SUMMARY
            echo "| Total Requests | ${REQS} |" >> $GITHUB_STEP_SUMMARY
          else
            echo "No K6 results found" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Locust Results" >> $GITHUB_STEP_SUMMARY
          echo "See attached artifacts for detailed Locust HTML report" >> $GITHUB_STEP_SUMMARY

      - name: Upload combined report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: performance-results/
          retention-days: 90
